"""
classification.ipynb

Adapted from:
    Automatically generated by Colaboratory.

    Original file is located at
        https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/classification.ipynb

    Copyright 2018 The TensorFlow Authors.
"""

import tensorflow as tf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.python.client import device_lib

import os
import cv2
import random
import numpy as np
import pandas as pd
from shutil import copyfile

BATCH_SIZE = 3
EPOCHS = 10
IMG_HEIGHT = 512
IMG_WIDTH = 512
TRAINING_SIZE = 120
VALIDATION_SIZE = 30
TRAINING_DIR = '../training'
VALIDATION_DIR = '../validation'


def clear_directory_files(folder):
    for filename in os.listdir(folder):
        file_path = os.path.join(folder, filename)

        if os.path.isfile(file_path) or os.path.islink(file_path):
            os.unlink(file_path)


def build_sets(info):
    training_abdominal_dir = os.path.join(TRAINING_DIR, 'abdominal')
    training_non_abdominal_dir = os.path.join(TRAINING_DIR, 'non_abdominal')
    validation_abdominal_dir = os.path.join(VALIDATION_DIR, 'abdominal')
    validation_non_abdominal_dir = os.path.join(VALIDATION_DIR, 'non_abdominal')

    # clear out directories
    clear_directory_files(training_abdominal_dir)
    clear_directory_files(training_non_abdominal_dir)
    clear_directory_files(validation_abdominal_dir)
    clear_directory_files(validation_non_abdominal_dir)

    processed_image_dir = '../processed_images'
    smoothed_image_dir = '../smoothed_images'

    abdominal_images = []
    non_abdominal_images = []

    image_to_type = {}

    for index, row in info.iterrows():
        image_to_type[row['File_name']] = row['Coarse_lesion_type']

    for filename in os.listdir(processed_image_dir):
        if image_to_type[filename] == 2:
            abdominal_images.append(filename)
        else:
            non_abdominal_images.append(filename)

    random_abdominal_images = random.sample(abdominal_images, TRAINING_SIZE + VALIDATION_SIZE)
    random_non_abdominal_images = random.sample(non_abdominal_images, TRAINING_SIZE + VALIDATION_SIZE)

    for index, image in enumerate(random_abdominal_images):
        if index < TRAINING_SIZE:
            src = os.path.join(processed_image_dir, image)
            dest = os.path.join(training_abdominal_dir, image)
        else:
            src = os.path.join(smoothed_image_dir, image)
            dest = os.path.join(validation_abdominal_dir, image)

        copyfile(src, dest)

    for index, image in enumerate(random_non_abdominal_images):
        if index < TRAINING_SIZE:
            src = os.path.join(processed_image_dir, image)
            dest = os.path.join(training_non_abdominal_dir, image)
        else:
            src = os.path.join(smoothed_image_dir, image)
            dest = os.path.join(validation_non_abdominal_dir, image)

        copyfile(src, dest)

    num_abdominal_training = len(os.listdir(training_abdominal_dir))
    num_non_abdominal_training = len(os.listdir(training_non_abdominal_dir))

    num_abdominal_validation = len(os.listdir(validation_abdominal_dir))
    num_non_abdominal_validation = len(os.listdir(validation_non_abdominal_dir))

    total_training = num_abdominal_training + num_non_abdominal_training
    total_validation = num_abdominal_validation + num_non_abdominal_validation

    print('total training abdominal images:', num_abdominal_training)
    print('total training non_abdominal images:', num_non_abdominal_training)

    print('total validation abdominal images:', num_abdominal_validation)
    print('total validation non_abdominal images:', num_non_abdominal_validation)

    print("--")
    print("Total training images:", total_training)
    print("Total validation images:", total_validation)

    return total_training, total_validation


def prepare_data():
    train_image_generator = ImageDataGenerator(rescale=1. / 255)  # Generator for our training data
    validation_image_generator = ImageDataGenerator(rescale=1. / 255)  # Generator for our validation data

    train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                               directory=TRAINING_DIR,
                                                               shuffle=True,
                                                               target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                               class_mode='binary')

    val_data_gen = validation_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                                  directory=VALIDATION_DIR,
                                                                  target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                                  class_mode='binary')

    return train_data_gen, val_data_gen


def build_model():
    model = Sequential([
        Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
        MaxPooling2D(),
        Conv2D(32, 3, padding='same', activation='relu'),
        MaxPooling2D(),
        Conv2D(64, 3, padding='same', activation='relu'),
        MaxPooling2D(),
        Flatten(),
        Dense(128, activation='relu'),
        Dense(1, activation='sigmoid')
    ])

    model.compile(optimizer='adam',
                  loss='binary_crossentropy',
                  metrics=['accuracy'])

    model.summary()

    return model


def train_model(model, train_data_gen, val_data_gen, total_train, total_val):
    model.fit_generator(
        train_data_gen,
        steps_per_epoch=total_train // BATCH_SIZE,
        epochs=EPOCHS,
        validation_data=val_data_gen,
        validation_steps=total_val // BATCH_SIZE
    )


if __name__ == "__main__":
    info = pd.read_csv('../info/info.csv')
    config = tf.compat.v1.ConfigProto()
    config.gpu_options.allow_growth = True
    sess = tf.compat.v1.Session(config=config)
    print('GPU & CPU devices:')
    print(device_lib.list_local_devices())

    total_train, total_val = build_sets(info)
    train_data_gen, val_data_gen = prepare_data()
    model = build_model()
    train_model(model, train_data_gen, val_data_gen, total_train, total_val)

    print('Model Accuracy:', model.evaluate(val_data_gen)[1])
